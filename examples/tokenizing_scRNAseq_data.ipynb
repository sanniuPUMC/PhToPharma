{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a91bca46-c056-4784-8c6c-b0f5d3f33496",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokenizing .loom single cell RNA-seq data to rank value encoding .dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080fdd9c-0c48-4d5d-a254-52b6c53cdf78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from geneformer import TranscriptomeTokenizer\n",
    "from pathlib import Path\n",
    "\n",
    "#loom_data_directory = Path(\"/webdav/MyData/Geneformer2/Genecorpus-30M/data/\")\n",
    "loom_data_directory = Path(\"/webdav/MyData/Geneformer2/Genecorpus-30M/data/susbet\")\n",
    "print(loom_data_directory.glob(\"*.loom\"))\n",
    "loom_data_directory.glob(\"*.loom\")\n",
    "list(loom_data_directory.glob(\"*.loom\"))\n",
    "output_directory = Path(\"/webdav/MyData/Geneformer2/Geneformer/data/out\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fcb702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 加载 pickle 文件\n",
    "with open(\"/webdav/MyData/Geneformer2/Geneformer/geneformer/token_dictionary.pkl\", \"rb\") as f:\n",
    "    token_dictionary = pickle.load(f)\n",
    "\n",
    "# 访问字典对象\n",
    "print(token_dictionary)  # 输出 hello 的标记 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U loompy\n",
    "!pip install pyensembl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "# load evaluation dataset (includes all tissues)\n",
    "eval_dataset=load_from_disk(\"/webdav/MyData/Geneformer2/Genecorpus-30M/genecorpus_30M_2048.dataset\")\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb7f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "eval_datas=load_from_disk(\"/webdav/MyData/Geneformer2/Geneformer/data/mydata/output_prefix.dataset\")\n",
    "eval_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef1825",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import loompy\n",
    "#ds = loompy.connect(\"/webdav/MyData/Geneformer2/Genecorpus-30M/data/l5_all.loom\")\n",
    "#ds = loompy.connect(\"/webdav/MyData/Geneformer2/Genecorpus-30M/data/susbet/1.loom\")\n",
    "ds = loompy.connect(\"/webdav/MyData/Geneformer2/Geneformer/data/loom12.loom\")\n",
    "\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b23e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[1,:]\n",
    "ds.ca.keys()\n",
    "#ds.ra.keys()\n",
    "layer_names = ds.layers.keys()\n",
    "# 打印层名称\n",
    "print(layer_names)\n",
    "#ds[2, :]   \n",
    "#ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce39a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = ds.layers.keys()\n",
    "# 打印层名称\n",
    "print(layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0d4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ra['Accession']\n",
    "ds\n",
    "ds.ra[\"filter_pass\"] = ds.ra[\"_Valid\"]\n",
    "ds.ca[\"filter_pass\"] \n",
    "ds.ra[\"ensembl_id\"] = ds.ra[\"Accession\"]\n",
    "ds.ca[\"n_counts\"] = ds.ca[\"_NGenes\"]\n",
    "ds.ca[\"cell_type\"] = ds.ca[\"Subclass\"]\n",
    "ds.ca[\"organ_major\"] = ds.ca[\"Tissue\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b4a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ra[\"ensembl_id\"] = ds.ra[\"Accession\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477610f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ca[\"n_counts\"] = ds.ca[\"_NGenes\"]\n",
    "ds.ca[\"cell_type\"] = ds.ca[\"Subclass\"]\n",
    "ds.ca[\"organ_major\"] = ds.ca[\"Tissue\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584999e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ca[\"Tissue\"].shape\n",
    "ds.ca[\"disease\"]\n",
    "ds[1:5,1:5]\n",
    "\n",
    "arr = ds[1:5000:,1:5000]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ds.ra[\"ensembl_id\", \"Gene\"] \n",
    "a\n",
    "# Returns a 2D array of shape (n_genes, 2)\n",
    "b = ds.ca    \n",
    "b\n",
    "# # Returns a 2D array of shape (n_cells, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import loompy\n",
    "import numpy as np\n",
    "\n",
    "filename = \"/webdav/MyData/Geneformer2/Genecorpus-30M/data/l5_all.loom\"\n",
    "new_filename = \"/webdav/MyData/Geneformer2/Genecorpus-30M/data/susbet/1.loom\"\n",
    "\n",
    "# Open the original Loom file\n",
    "with loompy.connect(filename) as ds:\n",
    "    # Get the first 100 rows and columns of the matrix\n",
    "    matrix = ds[:, :6000][:6000, :]\n",
    "    import numpy as np\n",
    "    matrix = matrix.astype(np.int64)\n",
    "    # Get the first 100 elements of the row and column attributes\n",
    "    col_attrs = { \"n_counts\": ds.ca[\"_NGenes\"][:6000].astype(np.int64), \"cell_type\":ds.ca[\"Subclass\"][:6000],\"organ_major\":ds.ca[\"Tissue\"][:6000],\"filter_pass\":ds.ca[\"filter_pass\"][:6000],\"disease\":ds.ca[\"disease\"][:6000]}\n",
    "    col_attrs\n",
    "    row_attrs = { \"ensembl_id\": ds.ra[\"Accession\"][:6000],\"filter_pass\": ds.ra[\"filter_pass\"][:6000]}\n",
    "    row_attrs\n",
    "\n",
    "# Create a new Loom file with the extracted data\n",
    "loompy.create(new_filename, matrix, row_attrs, col_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeecd9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ca[\"_NGenes\"][:6000]\n",
    "#ds.ca[\"filter_pass\"][:6000]\n",
    "\n",
    "print(matrix.dtype)\n",
    "\n",
    "print(ds.ra[\"filter_pass\"][:6000].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.ca[\"AnalysisProject\"]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 创建一个包含示例数据的 NumPy 数组\n",
    "arr = ds.ca[\"cell_type\"]\n",
    "\n",
    "# 使用 unique 函数获取唯一值\n",
    "unique_values = np.unique(arr)\n",
    "\n",
    "# 输出唯一值的数量\n",
    "print(unique_values)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#char_array = np.array(['dcm', 'nf', 'hcm'])\n",
    "ensembl_array = np.random.choice(['dcm', 'nf', 'hcm'], size=(160796,))\n",
    "#result_array = np.core.defchararray.add(char_array[np.random.choice(3, size=(160796,))], ensembl_array)\n",
    "ensembl_array\n",
    "# 转换数据类型为 object\n",
    "arr = ensembl_array.astype(object)\n",
    "# 查看转换后的数组\n",
    "print(arr)\n",
    "arr\n",
    "ds.ca[\"disease\"] = arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6657bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9641b146-af2c-4688-9d8a-9c570246d116",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = TranscriptomeTokenizer({\"cell_type\": \"cell_type\", \"organ_major\": \"organ_major\",'disease':'disease'}, nproc=10)   # Dictionary of custom attributes to be added to the dataset.\n",
    "tk.tokenize_data(loom_data_directory, output_directory, \"output_prefix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c49414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import loompy as lp\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "\n",
    "GENE_MEDIAN_FILE = Path(__file__).parent / \"gene_median_dictionary.pkl\"\n",
    "TOKEN_DICTIONARY_FILE = Path(__file__).parent / \"token_dictionary.pkl\"\n",
    "GENE_MEDIAN_FILE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gene]",
   "language": "python",
   "name": "conda-env-gene-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a5edab282632443219e051e4ade2d1d5bbc671c781051bf1437897cbdfea0f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
